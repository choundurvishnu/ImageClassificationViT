{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/choundurvishnu/ImageClassificationViT/blob/main/Untitled26.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sqilq6hjzia3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from transformers import ViTForImageClassification, ViTFeatureExtractor\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ya7ZNuM3zieL"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
        "     transforms.Lambda(lambda x: (x + 1) / 2),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H23W815czyOr"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_dataset = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YI1-Gq70zySY"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Step 2: Load pre-trained ViT model\n",
        "model_name = \"google/vit-base-patch16-224\"\n",
        "model = ViTForImageClassification.from_pretrained(model_name, num_labels=10,ignore_mismatched_sizes=True  # Ignore size mismatch in the final layer\n",
        ")\n",
        "#feature_extractor = ViTFeatureExtractor.from_pretrained(model_name)#\n",
        "feature_extractor = ViTFeatureExtractor.from_pretrained(model_name)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XhjT_LUazyVy"
      },
      "outputs": [],
      "source": [
        "# Step 3: Fine-tune the model (optional)\n",
        "\n",
        "optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "num_epochs = 3\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    total_iterations = len(train_loader)  # Total number of batches\n",
        "    for current_iteration, (images, labels) in enumerate(train_loader, 1):  # Start counting from 1\n",
        "        # Preprocess images using the feature extractor\n",
        "        inputs = feature_extractor(images, return_tensors=\"pt\")\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(**inputs)\n",
        "        loss = criterion(outputs.logits, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Calculate percentage completion\n",
        "        percentage_completion = (current_iteration / total_iterations) * 100\n",
        "\n",
        "        # Print progress\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Progress: {percentage_completion:.2f}%, Loss: {loss.item():.4f}\")\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Average Loss: {running_loss/len(train_loader)}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oMLPmkFdzyZQ"
      },
      "outputs": [],
      "source": [
        "# Step 4: Evaluate the model\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        inputs = feature_extractor(images, return_tensors=\"pt\")\n",
        "        outputs = model(**inputs)\n",
        "        _, predicted = torch.max(outputs.logits, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lr7wB2LNziqp"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMIChipC4ccv7wLYsARGrRB",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}